{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d537e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "\n",
    "dataset_path = 'fer2013.csv'\n",
    "image_size=(48,48)\n",
    "\n",
    "def load_fer():\n",
    "        data = pd.read_csv(dataset_path)\n",
    "        pixels = data['pixels'].tolist()\n",
    "        width, height = 48, 48\n",
    "        faces = []\n",
    "        for pixel_sequence in pixels:\n",
    "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(width, height)\n",
    "            face = cv2.resize(face.astype('uint8'),image_size)\n",
    "            faces.append(face.astype('float32'))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "        emotions = pd.get_dummies(data['emotion']).values\n",
    "        return faces, emotions\n",
    "\n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1af3929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 2304, 1)           0         \n",
      "                                                                 \n",
      " permute_3 (Permute)         (None, 1, 2304)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 1, 64)             606464    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 1, 64)             256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1, 64)             0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 640455 (2.44 MB)\n",
      "Trainable params: 640199 (2.44 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "897/898 [============================>.] - ETA: 0s - loss: 1.7955 - accuracy: 0.3171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gargi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/898 [==============================] - 38s 27ms/step - loss: 1.7955 - accuracy: 0.3171 - val_loss: 1.6833 - val_accuracy: 0.3548 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "898/898 [==============================] - 19s 21ms/step - loss: 1.6584 - accuracy: 0.3648 - val_loss: 1.6363 - val_accuracy: 0.3697 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "898/898 [==============================] - 19s 21ms/step - loss: 1.6063 - accuracy: 0.3796 - val_loss: 1.6060 - val_accuracy: 0.3823 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "898/898 [==============================] - 19s 21ms/step - loss: 1.5688 - accuracy: 0.3981 - val_loss: 1.5743 - val_accuracy: 0.3918 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "898/898 [==============================] - 19s 22ms/step - loss: 1.5405 - accuracy: 0.4076 - val_loss: 1.5812 - val_accuracy: 0.3888 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "898/898 [==============================] - 19s 21ms/step - loss: 1.5164 - accuracy: 0.4216 - val_loss: 1.5670 - val_accuracy: 0.3922 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "898/898 [==============================] - 17s 19ms/step - loss: 1.4970 - accuracy: 0.4291 - val_loss: 1.5632 - val_accuracy: 0.3957 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "898/898 [==============================] - 20s 22ms/step - loss: 1.4768 - accuracy: 0.4394 - val_loss: 1.5633 - val_accuracy: 0.3969 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "898/898 [==============================] - 19s 22ms/step - loss: 1.4561 - accuracy: 0.4459 - val_loss: 1.5514 - val_accuracy: 0.4065 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "898/898 [==============================] - 19s 21ms/step - loss: 1.4326 - accuracy: 0.4589 - val_loss: 1.5610 - val_accuracy: 0.4029 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "898/898 [==============================] - 19s 22ms/step - loss: 1.4100 - accuracy: 0.4683 - val_loss: 1.5597 - val_accuracy: 0.4011 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "898/898 [==============================] - 20s 22ms/step - loss: 1.3973 - accuracy: 0.4780 - val_loss: 1.5622 - val_accuracy: 0.4033 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "898/898 [==============================] - 20s 22ms/step - loss: 1.3748 - accuracy: 0.4849 - val_loss: 1.5526 - val_accuracy: 0.4079 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "898/898 [==============================] - 20s 23ms/step - loss: 1.3465 - accuracy: 0.4964 - val_loss: 1.5765 - val_accuracy: 0.4042 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.3321 - accuracy: 0.5052 - val_loss: 1.5650 - val_accuracy: 0.4078 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "898/898 [==============================] - 20s 23ms/step - loss: 1.3109 - accuracy: 0.5156 - val_loss: 1.5906 - val_accuracy: 0.4076 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "898/898 [==============================] - 21s 23ms/step - loss: 1.2933 - accuracy: 0.5211 - val_loss: 1.6165 - val_accuracy: 0.4014 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "898/898 [==============================] - 20s 23ms/step - loss: 1.2709 - accuracy: 0.5319 - val_loss: 1.5922 - val_accuracy: 0.4135 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "898/898 [==============================] - 20s 22ms/step - loss: 1.2511 - accuracy: 0.5413 - val_loss: 1.6177 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "898/898 [==============================] - 20s 22ms/step - loss: 1.2347 - accuracy: 0.5457 - val_loss: 1.6437 - val_accuracy: 0.4071 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f920404250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, BatchNormalization, Activation, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Reshape, Permute\n",
    "\n",
    "from keras.layers import Input, LSTM, Dense, BatchNormalization, Activation, Reshape, Permute\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def mini_XCEPTION_LSTM(input_shape, num_classes, l2_regularization=0.01):\n",
    "    img_input = Input(input_shape)\n",
    "\n",
    "    # Reshape the input to represent sequences over time\n",
    "    x = Reshape((input_shape[0] * input_shape[1], input_shape[2]))(img_input)\n",
    "    x = Permute((2, 1))(x)  # Transpose the input for LSTM\n",
    "\n",
    "    x = LSTM(64, return_sequences=True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = LSTM(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(num_classes, kernel_regularizer=l2(l2_regularization), activation='softmax')(x)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "input_shape = (48, 48, 1)  # Assuming you want to use the same input shape as before\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = 'models/'\n",
    "\n",
    "# data generator\n",
    "# (No changes needed if you are using the same data generator)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION_LSTM(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# callbacks\n",
    "# (No changes needed to callbacks)\n",
    "\n",
    "# loading dataset\n",
    "faces, emotions = load_fer()\n",
    "faces = preprocess_input(faces)\n",
    "num_samples, num_classes = emotions.shape\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.2, shuffle=True)\n",
    "# ... (previous code remains the same)\n",
    "\n",
    "# Assuming you have one-hot encoded ytrain and ytest\n",
    "\n",
    "# Define your callbacks\n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(\"models/_mini_XCEPTION.{epoch:02d}-{val_accuracy:.2f}.hdf5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "# Now you can fit the model\n",
    "model.fit(xtrain, ytrain,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epochs,\n",
    "          verbose=verbose,\n",
    "          validation_data=(xtest, ytest),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6735020e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

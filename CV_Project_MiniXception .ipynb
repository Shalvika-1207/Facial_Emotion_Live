{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5377d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "\n",
    "dataset_path = 'fer2013.csv'\n",
    "image_size=(48,48)\n",
    "\n",
    "def load_fer():\n",
    "        data = pd.read_csv(dataset_path)\n",
    "        pixels = data['pixels'].tolist()\n",
    "        width, height = 48, 48\n",
    "        faces = []\n",
    "        for pixel_sequence in pixels:\n",
    "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(width, height)\n",
    "            face = cv2.resize(face.astype('uint8'),image_size)\n",
    "            faces.append(face.astype('float32'))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "        emotions = pd.get_dummies(data['emotion']).values\n",
    "        return faces, emotions\n",
    "\n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6456b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "faces, emotions = load_fer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03faadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c599a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c1cd7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n",
    "    regularization = l2(l2_regularization)\n",
    "\n",
    "    # base\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # module 1\n",
    "    residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 2\n",
    "    residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 3\n",
    "    residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 4\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "            #kernel_regularizer=regularization,\n",
    "            padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax',name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "285dbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "input_shape = (48, 48, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a39730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 48, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 46, 46, 8)            72        ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 46, 46, 8)            32        ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 46, 46, 8)            0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 44, 44, 8)            576       ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 44, 44, 8)            32        ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 44, 44, 8)            0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d (Separabl  (None, 44, 44, 16)           200       ['activation_1[0][0]']        \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 44, 44, 16)           64        ['separable_conv2d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 44, 44, 16)           0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (Separa  (None, 44, 44, 16)           400       ['activation_2[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 44, 44, 16)           64        ['separable_conv2d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 16)           128       ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 22, 22, 16)           0         ['batch_normalization_4[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 22, 22, 16)           64        ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 22, 22, 16)           0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (Separa  (None, 22, 22, 32)           656       ['add[0][0]']                 \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 22, 22, 32)           128       ['separable_conv2d_2[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 22, 22, 32)           0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (Separa  (None, 22, 22, 32)           1312      ['activation_3[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 22, 22, 32)           128       ['separable_conv2d_3[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 32)           512       ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 11, 11, 32)           0         ['batch_normalization_7[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 11, 11, 32)           128       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 11, 11, 32)           0         ['max_pooling2d_1[0][0]',     \n",
      "                                                                     'batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (Separa  (None, 11, 11, 64)           2336      ['add_1[0][0]']               \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 11, 11, 64)           256       ['separable_conv2d_4[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 11, 11, 64)           0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (Separa  (None, 11, 11, 64)           4672      ['activation_4[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 11, 11, 64)           256       ['separable_conv2d_5[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 64)             2048      ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 64)             0         ['batch_normalization_10[0][0]\n",
      " g2D)                                                               ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 6, 6, 64)             256       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 6, 6, 64)             0         ['max_pooling2d_2[0][0]',     \n",
      "                                                                     'batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_6 (Separa  (None, 6, 6, 128)            8768      ['add_2[0][0]']               \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 6, 6, 128)            512       ['separable_conv2d_6[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 6, 6, 128)            0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " separable_conv2d_7 (Separa  (None, 6, 6, 128)            17536     ['activation_5[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 6, 6, 128)            512       ['separable_conv2d_7[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 3, 3, 128)            8192      ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 3, 3, 128)            0         ['batch_normalization_13[0][0]\n",
      " g2D)                                                               ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 3, 3, 128)            512       ['conv2d_5[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 3, 3, 128)            0         ['max_pooling2d_3[0][0]',     \n",
      "                                                                     'batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 3, 3, 7)              8071      ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 7)                    0         ['conv2d_6[0][0]']            \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " predictions (Activation)    (None, 7)                    0         ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 58423 (228.21 KB)\n",
      "Trainable params: 56951 (222.46 KB)\n",
      "Non-trainable params: 1472 (5.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a2ba9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gargi\\AppData\\Local\\Temp\\ipykernel_5952\\2687457697.py:18: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(data_generator.flow(xtrain, ytrain,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "898/897 [==============================] - ETA: 0s - loss: 1.7665 - accuracy: 0.3283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gargi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 203s 214ms/step - loss: 1.7665 - accuracy: 0.3283 - val_loss: 1.8344 - val_accuracy: 0.3826 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "897/897 [==============================] - 188s 209ms/step - loss: 1.4835 - accuracy: 0.4474 - val_loss: 1.5376 - val_accuracy: 0.4542 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "897/897 [==============================] - 188s 210ms/step - loss: 1.3730 - accuracy: 0.4896 - val_loss: 1.3296 - val_accuracy: 0.5086 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "897/897 [==============================] - 182s 203ms/step - loss: 1.3116 - accuracy: 0.5094 - val_loss: 1.3393 - val_accuracy: 0.5052 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "897/897 [==============================] - 181s 202ms/step - loss: 1.2626 - accuracy: 0.5274 - val_loss: 1.2491 - val_accuracy: 0.5373 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "897/897 [==============================] - 179s 199ms/step - loss: 1.2315 - accuracy: 0.5421 - val_loss: 1.3715 - val_accuracy: 0.5026 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "897/897 [==============================] - 179s 200ms/step - loss: 1.2061 - accuracy: 0.5476 - val_loss: 1.2231 - val_accuracy: 0.5397 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "897/897 [==============================] - 179s 199ms/step - loss: 1.1859 - accuracy: 0.5566 - val_loss: 1.1605 - val_accuracy: 0.5639 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "897/897 [==============================] - 184s 205ms/step - loss: 1.1667 - accuracy: 0.5635 - val_loss: 1.1256 - val_accuracy: 0.5777 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "897/897 [==============================] - 183s 204ms/step - loss: 1.1528 - accuracy: 0.5687 - val_loss: 1.1572 - val_accuracy: 0.5676 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "897/897 [==============================] - 181s 202ms/step - loss: 1.1392 - accuracy: 0.5762 - val_loss: 1.1510 - val_accuracy: 0.5761 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "897/897 [==============================] - 381s 425ms/step - loss: 1.1272 - accuracy: 0.5794 - val_loss: 1.1662 - val_accuracy: 0.5637 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "897/897 [==============================] - 181s 202ms/step - loss: 1.1184 - accuracy: 0.5810 - val_loss: 1.1536 - val_accuracy: 0.5713 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "897/897 [==============================] - 244s 272ms/step - loss: 1.1016 - accuracy: 0.5890 - val_loss: 1.1618 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "897/897 [==============================] - 183s 204ms/step - loss: 1.0981 - accuracy: 0.5909 - val_loss: 1.1443 - val_accuracy: 0.5713 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "897/897 [==============================] - 208s 232ms/step - loss: 1.0842 - accuracy: 0.5946 - val_loss: 1.0778 - val_accuracy: 0.5981 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "897/897 [==============================] - 184s 205ms/step - loss: 1.0772 - accuracy: 0.5989 - val_loss: 1.1110 - val_accuracy: 0.5907 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "897/897 [==============================] - 184s 205ms/step - loss: 1.0702 - accuracy: 0.6015 - val_loss: 1.1025 - val_accuracy: 0.5956 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "897/897 [==============================] - 182s 203ms/step - loss: 1.0653 - accuracy: 0.6019 - val_loss: 1.0754 - val_accuracy: 0.5904 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "897/897 [==============================] - 183s 203ms/step - loss: 1.0569 - accuracy: 0.6078 - val_loss: 1.1460 - val_accuracy: 0.5779 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x245c1976c10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # callbacks\n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(\"models/_mini_XCEPTION.{epoch:02d}-{val_accuracy:.2f}.hdf5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "# loading dataset\n",
    "faces, emotions = load_fer()\n",
    "faces = preprocess_input(faces)\n",
    "num_samples, num_classes = emotions.shape\n",
    "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(xtrain) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a4dbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# parameters for loading data and images\n",
    "detection_model_path = 'haarcascade_files/haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = 'models/_mini_XCEPTION.02-0.53.hdf5'\n",
    "\n",
    "# hyper-parameters for bounding boxes shape\n",
    "# loading models\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
    " \"neutral\"]\n",
    "\n",
    "\n",
    "#feelings_faces = []\n",
    "#for index, emotion in enumerate(EMOTIONS):\n",
    "   # feelings_faces.append(cv2.imread('emojis/' + emotion + '.png', -1))\n",
    "\n",
    "# starting video streaming\n",
    "cv2.namedWindow('your_face')\n",
    "camera = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    frame = camera.read()[1]\n",
    "    #reading the frame\n",
    "    frame = imutils.resize(frame,width=300)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
    "    frameClone = frame.copy()\n",
    "    if len(faces) > 0:\n",
    "        faces = sorted(faces, reverse=True,\n",
    "        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "        (fX, fY, fW, fH) = faces\n",
    "                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 28x28 pixels, and then prepare\n",
    "            # the ROI for classification via the CNN\n",
    "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
    "        roi = cv2.resize(roi, (48, 48))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        \n",
    "        \n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "    else: continue\n",
    "\n",
    " \n",
    "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "                # construct the label text\n",
    "                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
    "\n",
    "                # draw the label + probability bar on the canvas\n",
    "               # emoji_face = feelings_faces[np.argmax(preds)]\n",
    "\n",
    "                \n",
    "                w = int(prob * 300)\n",
    "                cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
    "                (w, (i * 35) + 35), (0, 0, 255), -1)\n",
    "                cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
    "                (255, 255, 255), 2)\n",
    "                cv2.putText(frameClone, label, (fX, fY - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "                cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
    "                              (0, 0, 255), 2)\n",
    "#    for c in range(0, 3):\n",
    "#        frame[200:320, 10:130, c] = emoji_face[:, :, c] * \\\n",
    "#        (emoji_face[:, :, 3] / 255.0) + frame[200:320,\n",
    "#        10:130, c] * (1.0 - emoji_face[:, :, 3] / 255.0)s\n",
    "\n",
    "\n",
    "    cv2.imshow('your_face', frameClone)\n",
    "    cv2.imshow(\"Probabilities\", canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "#press q to close the windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a8b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
